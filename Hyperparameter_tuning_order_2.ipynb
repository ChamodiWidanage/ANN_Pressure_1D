{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbb7fRy-eyr"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sNDnxE2-pwE"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxChR1Rk-umf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uBTqR3nacj0e",
    "outputId": "4c0bd183-e424-429a-9fba-ceb841c06888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG3FQEch-yuA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4zq8Mza_D9O"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9CV13Co_HHM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_type        546 non-null    object \n",
      " 1   Charge_size        546 non-null    float64\n",
      " 2   Standoff_distance  546 non-null    float64\n",
      " 3   Incident_pressure  546 non-null    float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('Dataset3.xlsx')\n",
    "dataset.info()\n",
    "\n",
    "#X=X.to_list()\n",
    "\n",
    "#y=y.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_size        546 non-null    float64\n",
      " 1   Standoff_distance  546 non-null    float64\n",
      " 2   Incident_pressure  546 non-null    float64\n",
      " 3   Charge_type_CompB  546 non-null    uint8  \n",
      " 4   Charge_type_TNT    546 non-null    uint8  \n",
      "dtypes: float64(3), uint8(2)\n",
      "memory usage: 14.0 KB\n"
     ]
    }
   ],
   "source": [
    "# convert categorical variable into dummy variables\n",
    "dataset = pd.get_dummies(dataset, columns=['Charge_type'])\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Charge_size</th>\n",
       "      <th>Standoff_distance</th>\n",
       "      <th>Incident_pressure</th>\n",
       "      <th>Charge_type_CompB</th>\n",
       "      <th>Charge_type_TNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>283.258</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>163.904</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>135.678</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>124.039</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>117.856</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Charge_size  Standoff_distance  Incident_pressure  Charge_type_CompB  \\\n",
       "0          0.5                1.5            283.258                  0   \n",
       "1          0.5                2.5            163.904                  0   \n",
       "2          0.5                3.5            135.678                  0   \n",
       "3          0.5                4.5            124.039                  0   \n",
       "4          0.5                5.5            117.856                  0   \n",
       "\n",
       "   Charge_type_TNT  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 4) (546,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset['Incident_pressure']\n",
    "X = dataset.drop('Incident_pressure', axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC6omXel_Up0"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#X_train=np.asarray(X_train).astype(np.int)\n",
    "\n",
    "#y_train=np.asarray(y_train).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning - batch size, epoch, optimizer, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer):\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=200, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " model.add(Dense(units=100, activation='relu'))\n",
    " model.add(Dense(units=50, activation='relu'))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    " # Compile model\n",
    " model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mae'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.926988 using {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.514319 (0.033408) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.511042 (0.038561) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.513524 (0.019911) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "-0.085578 (0.033590) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "-0.111314 (0.023026) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "-0.088138 (0.028595) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.177828 (0.034700) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.178505 (0.033505) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.178489 (0.034064) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.618492 (0.034574) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.577842 (0.033663) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.593154 (0.025785) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.101976 (0.015695) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.096080 (0.031886) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.110631 (0.026317) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.652038 (0.028558) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.674988 (0.061977) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.664737 (0.023100) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.820002 (0.078831) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.815634 (0.019188) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.836447 (0.062739) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "-0.036272 (0.029591) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "-0.033412 (0.039983) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "-0.031218 (0.023974) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.176540 (0.033786) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.121430 (0.097871) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.167732 (0.042317) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.899806 (0.040939) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.900019 (0.017778) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.909759 (0.021435) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.431860 (0.013124) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.415678 (0.055573) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.450106 (0.008423) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.916991 (0.023990) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.905903 (0.024431) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.926988 (0.026272) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.408012 (0.007202) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.406250 (0.079655) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.416490 (0.030159) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "-0.105508 (0.027041) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "-0.097922 (0.024663) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "-0.098552 (0.027690) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.177975 (0.033737) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.178010 (0.034388) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.178855 (0.033434) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.515675 (0.072289) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.491999 (0.061604) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.540434 (0.021264) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.059090 (0.032283) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.047076 (0.022401) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.071685 (0.053562) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.567545 (0.028360) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.600012 (0.033899) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.579444 (0.032940) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.761732 (0.069254) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.790962 (0.042884) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.751721 (0.085101) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "-0.040197 (0.016547) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "-0.055737 (0.026380) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "-0.046307 (0.027870) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.177061 (0.034528) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.177434 (0.033217) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.177117 (0.033258) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.876101 (0.027104) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.875963 (0.009199) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.855117 (0.030150) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.377899 (0.029144) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.367140 (0.008240) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.350283 (0.083143) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.891387 (0.032440) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.893862 (0.023958) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.907650 (0.020560) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.347457 (0.049689) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.334334 (0.055567) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.295329 (0.022174) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "-0.124126 (0.037176) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "-0.110514 (0.032675) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "-0.113655 (0.020077) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.176565 (0.033515) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.179034 (0.033459) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.177424 (0.034717) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.332248 (0.029065) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.382790 (0.010271) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.441491 (0.035892) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.048402 (0.039746) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.022840 (0.039405) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.040603 (0.017618) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.465617 (0.015515) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.480607 (0.024712) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.510165 (0.026606) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.710105 (0.045477) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.693784 (0.007544) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.664703 (0.019866) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "-0.051293 (0.029004) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "-0.053787 (0.023810) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "-0.058192 (0.022474) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.177953 (0.033267) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.178597 (0.034922) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.177293 (0.034280) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.812273 (0.027403) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.800996 (0.029270) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.834313 (0.035448) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.259264 (0.030720) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.255257 (0.021536) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.297219 (0.020525) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.821893 (0.032569) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.837669 (0.032206) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.847087 (0.021536) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.239274 (0.019579) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.262547 (0.032214) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.293536 (0.033363) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "-0.133645 (0.031730) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "-0.132781 (0.037955) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "-0.133010 (0.033432) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.178540 (0.033552) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.177116 (0.034691) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.177983 (0.033566) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.232003 (0.047089) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.249639 (0.013972) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.254774 (0.029101) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "-0.005929 (0.028491) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "-0.014215 (0.026152) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "-0.005683 (0.015434) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.373885 (0.028180) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.386100 (0.048090) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.336705 (0.017470) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.593464 (0.032347) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.613298 (0.017426) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.621610 (0.046098) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "-0.099239 (0.030421) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "-0.080545 (0.026771) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "-0.075846 (0.035535) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.178423 (0.033909) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.178978 (0.033024) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.177516 (0.034291) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.680989 (0.030441) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.694435 (0.017103) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.682671 (0.004317) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.191338 (0.057976) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.151998 (0.049669) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.179491 (0.041853) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.767320 (0.037043) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.742875 (0.024265) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.767977 (0.027193) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [50, 60, 80, 100]\n",
    "epochs = [100, 200, 400]\n",
    "optimizer = ['RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "\n",
    "# gridsearch\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, model__optimizer=optimizer, optimizer__learning_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning - optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer):\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=200, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " model.add(Dense(units=100, activation='relu'))\n",
    " model.add(Dense(units=50, activation='relu'))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    " # Compile model\n",
    " model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mae'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.159234 using {'model__optimizer': 'RMSprop'}\n",
      "-0.159234 (0.035652) with: {'model__optimizer': 'RMSprop'}\n",
      "-0.175333 (0.034729) with: {'model__optimizer': 'Adagrad'}\n",
      "-0.178695 (0.033541) with: {'model__optimizer': 'Adadelta'}\n",
      "-0.171589 (0.035585) with: {'model__optimizer': 'Adam'}\n",
      "-0.175102 (0.032544) with: {'model__optimizer': 'Adamax'}\n",
      "-0.171399 (0.032225) with: {'model__optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = ['RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "# gridsearch\n",
    "param_grid = dict(model__optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning - batch size, epoch, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=200, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " model.add(Dense(units=100, activation='relu'))\n",
    " model.add(Dense(units=50, activation='relu'))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.997277 using {'batch_size': 60, 'epochs': 100, 'optimizer__learning_rate': 0.01}\n",
      "0.976974 (0.017614) with: {'batch_size': 50, 'epochs': 50, 'optimizer__learning_rate': 0.01}\n",
      "0.934511 (0.048929) with: {'batch_size': 50, 'epochs': 50, 'optimizer__learning_rate': 0.1}\n",
      "0.289896 (0.414893) with: {'batch_size': 50, 'epochs': 50, 'optimizer__learning_rate': 0.2}\n",
      "0.996621 (0.002431) with: {'batch_size': 50, 'epochs': 100, 'optimizer__learning_rate': 0.01}\n",
      "0.880614 (0.097619) with: {'batch_size': 50, 'epochs': 100, 'optimizer__learning_rate': 0.1}\n",
      "0.299880 (0.426459) with: {'batch_size': 50, 'epochs': 100, 'optimizer__learning_rate': 0.2}\n",
      "0.992978 (0.004278) with: {'batch_size': 60, 'epochs': 50, 'optimizer__learning_rate': 0.01}\n",
      "0.970004 (0.009733) with: {'batch_size': 60, 'epochs': 50, 'optimizer__learning_rate': 0.1}\n",
      "0.298315 (0.438947) with: {'batch_size': 60, 'epochs': 50, 'optimizer__learning_rate': 0.2}\n",
      "0.997277 (0.001802) with: {'batch_size': 60, 'epochs': 100, 'optimizer__learning_rate': 0.01}\n",
      "0.936912 (0.033862) with: {'batch_size': 60, 'epochs': 100, 'optimizer__learning_rate': 0.1}\n",
      "0.303367 (0.446741) with: {'batch_size': 60, 'epochs': 100, 'optimizer__learning_rate': 0.2}\n",
      "0.972010 (0.019859) with: {'batch_size': 80, 'epochs': 50, 'optimizer__learning_rate': 0.01}\n",
      "0.882566 (0.084669) with: {'batch_size': 80, 'epochs': 50, 'optimizer__learning_rate': 0.1}\n",
      "0.375773 (0.338420) with: {'batch_size': 80, 'epochs': 50, 'optimizer__learning_rate': 0.2}\n",
      "0.980654 (0.021292) with: {'batch_size': 80, 'epochs': 100, 'optimizer__learning_rate': 0.01}\n",
      "0.948337 (0.040130) with: {'batch_size': 80, 'epochs': 100, 'optimizer__learning_rate': 0.1}\n",
      "-0.005370 (0.000900) with: {'batch_size': 80, 'epochs': 100, 'optimizer__learning_rate': 0.2}\n",
      "0.962241 (0.020736) with: {'batch_size': 100, 'epochs': 50, 'optimizer__learning_rate': 0.01}\n",
      "0.897146 (0.040488) with: {'batch_size': 100, 'epochs': 50, 'optimizer__learning_rate': 0.1}\n",
      "0.303355 (0.433063) with: {'batch_size': 100, 'epochs': 50, 'optimizer__learning_rate': 0.2}\n",
      "0.993725 (0.005130) with: {'batch_size': 100, 'epochs': 100, 'optimizer__learning_rate': 0.01}\n",
      "0.911065 (0.001954) with: {'batch_size': 100, 'epochs': 100, 'optimizer__learning_rate': 0.1}\n",
      "-0.004303 (0.002623) with: {'batch_size': 100, 'epochs': 100, 'optimizer__learning_rate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasRegressor(model=create_model, verbose=0, optimizer = 'Nadam', loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [50, 60, 80, 100]\n",
    "epochs = [50, 100, 200]\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "#momentum = [0.8, 0.9]\n",
    "\n",
    "# gridsearch\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer__learning_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - layers, neurons, activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor as KR\n",
    "import math\n",
    "def FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes):\n",
    "    layers = []\n",
    "    \n",
    "    nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
    "    nodes = first_layer_nodes\n",
    "    for i in range(1, n_layers+1):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chathura Gamage\\AppData\\Local\\Temp\\ipykernel_8804\\3554308760.py:16: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KR(build_fn=create_model, verbose=0, epochs = 100, batch_size = 50)\n"
     ]
    }
   ],
   "source": [
    "def create_model(n_layers, first_layer_nodes, last_layer_nodes, activation_func):\n",
    "    model = Sequential()\n",
    "    n_nodes = FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    for i in range(1, n_layers):\n",
    "        if i==1:\n",
    "            model.add(Dense(units = first_layer_nodes,  input_shape=(X_train.shape[1],), activation=activation_func))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            \n",
    "    #Finally, the output layer should have a single node in binary classification\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer = 'Nadam', loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "##Wrap model into scikit-learn\n",
    "model = KR(build_fn=create_model, verbose=0, epochs = 100, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001790A935550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001790A8F0940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best: 0.783874 using {'activation_func': 'softplus', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.132319 (0.094155) with: {'activation_func': 'relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.682773 (0.074640) with: {'activation_func': 'relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.184881 (0.100710) with: {'activation_func': 'relu', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.775430 (0.062576) with: {'activation_func': 'relu', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.216968 (0.124163) with: {'activation_func': 'softplus', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.749882 (0.044436) with: {'activation_func': 'softplus', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.292555 (0.144161) with: {'activation_func': 'softplus', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.783874 (0.081192) with: {'activation_func': 'softplus', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.123756 (0.099848) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.651654 (0.071981) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.162287 (0.114037) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.722030 (0.067203) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n"
     ]
    }
   ],
   "source": [
    "activation_funcs = ['relu', 'softplus', 'leaky_relu'] \n",
    "param_grid = dict(n_layers=[2,3], first_layer_nodes = [200,300], last_layer_nodes = [50],  activation_func = activation_funcs)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, scoring = 'r2')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(activation):\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=200, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " model.add(Dense(units=100, activation=activation))\n",
    " model.add(Dense(units=50, activation=activation))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 1s 2ms/step - loss: 1256468.5000 - mean_absolute_error: 426.5122\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1246645.7500 - mean_absolute_error: 415.3282\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1224792.5000 - mean_absolute_error: 383.7802\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1186158.5000 - mean_absolute_error: 338.8641\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1140074.6250 - mean_absolute_error: 355.0852\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1098556.0000 - mean_absolute_error: 388.8004\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1066248.6250 - mean_absolute_error: 422.2853\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1040176.3750 - mean_absolute_error: 432.2730\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1004930.0000 - mean_absolute_error: 407.1593\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 970431.8750 - mean_absolute_error: 408.7656\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 931707.0625 - mean_absolute_error: 399.3288\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 888128.0625 - mean_absolute_error: 389.7508\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 846687.0000 - mean_absolute_error: 388.2586\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 809631.0000 - mean_absolute_error: 387.9988\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 767896.7500 - mean_absolute_error: 359.8344\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 729878.2500 - mean_absolute_error: 342.8294\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 698016.3750 - mean_absolute_error: 338.6299\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 657561.3750 - mean_absolute_error: 312.7389\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 635241.8125 - mean_absolute_error: 288.1122\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 604261.3750 - mean_absolute_error: 290.9703\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 572853.3125 - mean_absolute_error: 284.9992\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 547324.0625 - mean_absolute_error: 275.8044\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 519138.8750 - mean_absolute_error: 268.1048\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 499808.5938 - mean_absolute_error: 264.3714\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 473909.2812 - mean_absolute_error: 256.8342\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 455340.5000 - mean_absolute_error: 257.1464\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 431925.1875 - mean_absolute_error: 247.2202\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 420247.7812 - mean_absolute_error: 241.4973\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 394483.0938 - mean_absolute_error: 230.7908\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 384006.6562 - mean_absolute_error: 232.2338\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 356659.5938 - mean_absolute_error: 222.8602\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 340026.9062 - mean_absolute_error: 212.7960\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 323634.6875 - mean_absolute_error: 206.8331\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 310406.0625 - mean_absolute_error: 207.5230\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 295325.5938 - mean_absolute_error: 200.3456\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 278386.3125 - mean_absolute_error: 189.4297\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 271163.5000 - mean_absolute_error: 187.7581\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 254501.7969 - mean_absolute_error: 179.9699\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 240761.5938 - mean_absolute_error: 172.2129\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 224666.4219 - mean_absolute_error: 164.6425\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 214841.8906 - mean_absolute_error: 160.8259\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 206473.2812 - mean_absolute_error: 154.2687\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 198798.9375 - mean_absolute_error: 153.3830\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 183462.7812 - mean_absolute_error: 139.6444\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 178478.5625 - mean_absolute_error: 138.9082\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 168116.6250 - mean_absolute_error: 132.7820\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 159074.9375 - mean_absolute_error: 130.9984\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 145919.0156 - mean_absolute_error: 120.6793\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 147612.9531 - mean_absolute_error: 121.5791\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 132702.1875 - mean_absolute_error: 113.3021\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 126361.0156 - mean_absolute_error: 111.8536\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 123618.0000 - mean_absolute_error: 108.0395\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 113708.8047 - mean_absolute_error: 103.9978\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 115604.1953 - mean_absolute_error: 111.3701\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 108044.8359 - mean_absolute_error: 102.4791\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 111573.4688 - mean_absolute_error: 101.2387\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 94252.2812 - mean_absolute_error: 95.5096\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 90185.9609 - mean_absolute_error: 94.0369\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 85748.5859 - mean_absolute_error: 91.5538\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 82679.0078 - mean_absolute_error: 89.0117\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 77843.9688 - mean_absolute_error: 88.7264\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79742.1484 - mean_absolute_error: 86.6764\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 70751.8750 - mean_absolute_error: 81.7256\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 74364.9688 - mean_absolute_error: 84.7376\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 71659.6328 - mean_absolute_error: 82.6294\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 66262.9219 - mean_absolute_error: 80.5274\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 59163.7383 - mean_absolute_error: 77.8923\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 60877.7031 - mean_absolute_error: 79.8385\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 61400.0977 - mean_absolute_error: 76.8868\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 58292.8086 - mean_absolute_error: 76.5133\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 55645.1562 - mean_absolute_error: 73.8487\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 57190.3359 - mean_absolute_error: 76.9535\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 50737.1289 - mean_absolute_error: 71.6513\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 52602.9141 - mean_absolute_error: 72.5721\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 48752.5508 - mean_absolute_error: 68.8158\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 49785.4453 - mean_absolute_error: 71.7316\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 53112.4141 - mean_absolute_error: 72.9508\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 46243.8906 - mean_absolute_error: 69.8546\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 42644.7734 - mean_absolute_error: 66.4187\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 43932.7930 - mean_absolute_error: 70.7579\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 44148.6836 - mean_absolute_error: 70.4933\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 41020.5742 - mean_absolute_error: 67.2787\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 38256.6602 - mean_absolute_error: 64.2617\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 41948.1250 - mean_absolute_error: 67.6940\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 38331.0586 - mean_absolute_error: 64.9321\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 35769.0391 - mean_absolute_error: 65.8282\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 40673.6133 - mean_absolute_error: 67.5306\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 34961.3359 - mean_absolute_error: 61.6376\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 32149.5488 - mean_absolute_error: 61.9934\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 31390.5918 - mean_absolute_error: 59.2297\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 30697.9199 - mean_absolute_error: 60.0540\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 31475.5625 - mean_absolute_error: 61.8019\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 30402.6621 - mean_absolute_error: 60.2105\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 31489.6660 - mean_absolute_error: 61.2918\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 26490.9316 - mean_absolute_error: 57.5881\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 31887.0273 - mean_absolute_error: 61.6377\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28743.6680 - mean_absolute_error: 58.4272\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 26025.5020 - mean_absolute_error: 55.5278\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 29592.7500 - mean_absolute_error: 59.8802\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 25450.2480 - mean_absolute_error: 55.6352\n",
      "Best: 0.937154 using {'model__activation': 'softplus'}\n",
      "0.911777 (0.033704) with: {'model__activation': 'relu'}\n",
      "0.937154 (0.019665) with: {'model__activation': 'softplus'}\n",
      "0.897905 (0.043656) with: {'model__activation': 'leaky_relu'}\n",
      "-0.148392 (0.030089) with: {'model__activation': 'tanh'}\n",
      "0.886524 (0.060647) with: {'model__activation': 'swish'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "from tensorflow import keras\n",
    "opt = keras.optimizers.Nadam(learning_rate=0.1)\n",
    "model = KerasRegressor(model=create_model, verbose=0, optimizer = 'Nadam', loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "# define the grid search parameters\n",
    "activation = ['relu', 'softplus', 'leaky_relu', 'tanh','swish'] \n",
    "\n",
    "# gridsearch\n",
    "param_grid = dict(model__activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train,\n",
    "                       epochs=100,\n",
    "                       batch_size=50,\n",
    "                       verbose=1)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
