{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbb7fRy-eyr"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sNDnxE2-pwE"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxChR1Rk-umf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uBTqR3nacj0e",
    "outputId": "4c0bd183-e424-429a-9fba-ceb841c06888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG3FQEch-yuA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4zq8Mza_D9O"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9CV13Co_HHM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_type        546 non-null    object \n",
      " 1   Charge_size        546 non-null    float64\n",
      " 2   Standoff_distance  546 non-null    float64\n",
      " 3   Incident_pressure  546 non-null    float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('Dataset3.xlsx')\n",
    "dataset.info()\n",
    "\n",
    "#X=X.to_list()\n",
    "\n",
    "#y=y.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_size        546 non-null    float64\n",
      " 1   Standoff_distance  546 non-null    float64\n",
      " 2   Incident_pressure  546 non-null    float64\n",
      " 3   Charge_type_CompB  546 non-null    uint8  \n",
      " 4   Charge_type_TNT    546 non-null    uint8  \n",
      "dtypes: float64(3), uint8(2)\n",
      "memory usage: 14.0 KB\n"
     ]
    }
   ],
   "source": [
    "# convert categorical variable into dummy variables\n",
    "dataset = pd.get_dummies(dataset, columns=['Charge_type'])\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Charge_size</th>\n",
       "      <th>Standoff_distance</th>\n",
       "      <th>Incident_pressure</th>\n",
       "      <th>Charge_type_CompB</th>\n",
       "      <th>Charge_type_TNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>283.258</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>163.904</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>135.678</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>124.039</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>117.856</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Charge_size  Standoff_distance  Incident_pressure  Charge_type_CompB  \\\n",
       "0          0.5                1.5            283.258                  0   \n",
       "1          0.5                2.5            163.904                  0   \n",
       "2          0.5                3.5            135.678                  0   \n",
       "3          0.5                4.5            124.039                  0   \n",
       "4          0.5                5.5            117.856                  0   \n",
       "\n",
       "   Charge_type_TNT  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 4) (546,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset['Incident_pressure']\n",
    "X = dataset.drop('Incident_pressure', axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC6omXel_Up0"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#X_train=np.asarray(X_train).astype(np.int)\n",
    "\n",
    "#y_train=np.asarray(y_train).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning - batch size, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=200, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " model.add(Dense(units=100, activation='relu'))\n",
    " model.add(Dense(units=50, activation='relu'))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    " # Compile model\n",
    " model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mae'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.899693 using {'batch_size': 50, 'epochs': 100}\n",
      "0.606975 (0.058195) with: {'batch_size': 50, 'epochs': 50}\n",
      "0.899693 (0.036065) with: {'batch_size': 50, 'epochs': 100}\n",
      "0.519128 (0.064557) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.886910 (0.035174) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.420370 (0.033439) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.780197 (0.018335) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.230609 (0.060922) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.671310 (0.059418) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [50, 60, 80, 100]\n",
    "epochs = [50, 100]\n",
    "\n",
    "# gridsearch\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning - batch size, epoch, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer):\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=200, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " model.add(Dense(units=100, activation='relu'))\n",
    " model.add(Dense(units=50, activation='relu'))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    " # Compile model\n",
    " model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mae'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.914535 using {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Nadam'}\n",
      "0.496583 (0.063779) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'RMSprop'}\n",
      "-0.096527 (0.037340) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adagrad'}\n",
      "-0.177245 (0.033484) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adadelta'}\n",
      "0.565627 (0.041256) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adam'}\n",
      "0.093906 (0.024753) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Adamax'}\n",
      "0.647086 (0.014402) with: {'batch_size': 50, 'epochs': 50, 'model__optimizer': 'Nadam'}\n",
      "0.827143 (0.058647) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'RMSprop'}\n",
      "-0.029085 (0.027905) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adagrad'}\n",
      "-0.174960 (0.035933) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adadelta'}\n",
      "0.909620 (0.031926) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adam'}\n",
      "0.390663 (0.036934) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adamax'}\n",
      "0.914535 (0.029798) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Nadam'}\n",
      "0.442997 (0.023217) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'RMSprop'}\n",
      "-0.101055 (0.024491) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adagrad'}\n",
      "-0.178178 (0.034219) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adadelta'}\n",
      "0.505676 (0.062691) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adam'}\n",
      "0.032634 (0.038819) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Adamax'}\n",
      "0.599719 (0.050026) with: {'batch_size': 60, 'epochs': 50, 'model__optimizer': 'Nadam'}\n",
      "0.768613 (0.090418) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'RMSprop'}\n",
      "-0.041048 (0.038258) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adagrad'}\n",
      "-0.178923 (0.033655) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adadelta'}\n",
      "0.887179 (0.023937) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adam'}\n",
      "0.348004 (0.039345) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adamax'}\n",
      "0.897097 (0.022544) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Nadam'}\n",
      "0.360691 (0.042681) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'RMSprop'}\n",
      "-0.107751 (0.021734) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adagrad'}\n",
      "-0.178331 (0.034849) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adadelta'}\n",
      "0.411161 (0.028814) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adam'}\n",
      "0.028398 (0.041969) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Adamax'}\n",
      "0.486604 (0.010256) with: {'batch_size': 80, 'epochs': 50, 'model__optimizer': 'Nadam'}\n",
      "0.684793 (0.053550) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'RMSprop'}\n",
      "-0.068670 (0.037840) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adagrad'}\n",
      "-0.167205 (0.024056) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adadelta'}\n",
      "0.822204 (0.019738) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adam'}\n",
      "0.288864 (0.038326) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adamax'}\n",
      "0.833304 (0.019069) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Nadam'}\n",
      "0.220382 (0.060127) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'RMSprop'}\n",
      "-0.131247 (0.029894) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adagrad'}\n",
      "-0.178011 (0.033414) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adadelta'}\n",
      "0.237975 (0.039182) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adam'}\n",
      "-0.000679 (0.030570) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Adamax'}\n",
      "0.352225 (0.058892) with: {'batch_size': 100, 'epochs': 50, 'model__optimizer': 'Nadam'}\n",
      "0.610918 (0.043800) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'RMSprop'}\n",
      "-0.085072 (0.036734) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adagrad'}\n",
      "-0.178308 (0.034469) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adadelta'}\n",
      "0.681888 (0.046357) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adam'}\n",
      "0.196195 (0.029271) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adamax'}\n",
      "0.732172 (0.021059) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [50, 60, 80, 100]\n",
    "epochs = [50, 100]\n",
    "optimizer = ['RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "# gridsearch\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, model__optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning - batch size, epoch, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=200, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " model.add(Dense(units=100, activation='relu'))\n",
    " model.add(Dense(units=50, activation='relu'))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.997277 using {'batch_size': 60, 'epochs': 100, 'optimizer__learning_rate': 0.01}\n",
      "0.976974 (0.017614) with: {'batch_size': 50, 'epochs': 50, 'optimizer__learning_rate': 0.01}\n",
      "0.934511 (0.048929) with: {'batch_size': 50, 'epochs': 50, 'optimizer__learning_rate': 0.1}\n",
      "0.289896 (0.414893) with: {'batch_size': 50, 'epochs': 50, 'optimizer__learning_rate': 0.2}\n",
      "0.996621 (0.002431) with: {'batch_size': 50, 'epochs': 100, 'optimizer__learning_rate': 0.01}\n",
      "0.880614 (0.097619) with: {'batch_size': 50, 'epochs': 100, 'optimizer__learning_rate': 0.1}\n",
      "0.299880 (0.426459) with: {'batch_size': 50, 'epochs': 100, 'optimizer__learning_rate': 0.2}\n",
      "0.992978 (0.004278) with: {'batch_size': 60, 'epochs': 50, 'optimizer__learning_rate': 0.01}\n",
      "0.970004 (0.009733) with: {'batch_size': 60, 'epochs': 50, 'optimizer__learning_rate': 0.1}\n",
      "0.298315 (0.438947) with: {'batch_size': 60, 'epochs': 50, 'optimizer__learning_rate': 0.2}\n",
      "0.997277 (0.001802) with: {'batch_size': 60, 'epochs': 100, 'optimizer__learning_rate': 0.01}\n",
      "0.936912 (0.033862) with: {'batch_size': 60, 'epochs': 100, 'optimizer__learning_rate': 0.1}\n",
      "0.303367 (0.446741) with: {'batch_size': 60, 'epochs': 100, 'optimizer__learning_rate': 0.2}\n",
      "0.972010 (0.019859) with: {'batch_size': 80, 'epochs': 50, 'optimizer__learning_rate': 0.01}\n",
      "0.882566 (0.084669) with: {'batch_size': 80, 'epochs': 50, 'optimizer__learning_rate': 0.1}\n",
      "0.375773 (0.338420) with: {'batch_size': 80, 'epochs': 50, 'optimizer__learning_rate': 0.2}\n",
      "0.980654 (0.021292) with: {'batch_size': 80, 'epochs': 100, 'optimizer__learning_rate': 0.01}\n",
      "0.948337 (0.040130) with: {'batch_size': 80, 'epochs': 100, 'optimizer__learning_rate': 0.1}\n",
      "-0.005370 (0.000900) with: {'batch_size': 80, 'epochs': 100, 'optimizer__learning_rate': 0.2}\n",
      "0.962241 (0.020736) with: {'batch_size': 100, 'epochs': 50, 'optimizer__learning_rate': 0.01}\n",
      "0.897146 (0.040488) with: {'batch_size': 100, 'epochs': 50, 'optimizer__learning_rate': 0.1}\n",
      "0.303355 (0.433063) with: {'batch_size': 100, 'epochs': 50, 'optimizer__learning_rate': 0.2}\n",
      "0.993725 (0.005130) with: {'batch_size': 100, 'epochs': 100, 'optimizer__learning_rate': 0.01}\n",
      "0.911065 (0.001954) with: {'batch_size': 100, 'epochs': 100, 'optimizer__learning_rate': 0.1}\n",
      "-0.004303 (0.002623) with: {'batch_size': 100, 'epochs': 100, 'optimizer__learning_rate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasRegressor(model=create_model, verbose=0, optimizer = 'Nadam', loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [50, 60, 80, 100]\n",
    "epochs = [50, 100]\n",
    "learn_rate = [0.01, 0.1, 0.2]\n",
    "#momentum = [0.8, 0.9]\n",
    "\n",
    "# gridsearch\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer__learning_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
