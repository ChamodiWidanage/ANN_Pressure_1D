{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbb7fRy-eyr"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sNDnxE2-pwE"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxChR1Rk-umf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG3FQEch-yuA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4zq8Mza_D9O"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9CV13Co_HHM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_type        546 non-null    object \n",
      " 1   Charge_size        546 non-null    float64\n",
      " 2   Standoff_distance  546 non-null    float64\n",
      " 3   Incident_pressure  546 non-null    float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('Dataset3.xlsx')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_size        546 non-null    float64\n",
      " 1   Standoff_distance  546 non-null    float64\n",
      " 2   Incident_pressure  546 non-null    float64\n",
      " 3   Charge_type_CompB  546 non-null    uint8  \n",
      " 4   Charge_type_TNT    546 non-null    uint8  \n",
      "dtypes: float64(3), uint8(2)\n",
      "memory usage: 14.0 KB\n"
     ]
    }
   ],
   "source": [
    "# convert categorical variable into dummy variables\n",
    "dataset = pd.get_dummies(dataset, columns=['Charge_type'])\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 4) (546,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset['Incident_pressure']\n",
    "X = dataset.drop('Incident_pressure', axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC6omXel_Up0"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - layers, neurons, activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor as KR\n",
    "import math\n",
    "def FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes):\n",
    "    layers = []\n",
    "    \n",
    "    nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
    "    nodes = first_layer_nodes\n",
    "    for i in range(1, n_layers+1):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chathura Gamage\\AppData\\Local\\Temp\\ipykernel_17368\\1602927943.py:18: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KR(build_fn=create_model, verbose=0, epochs = 500, batch_size = 50)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_model(n_layers, first_layer_nodes, last_layer_nodes, activation_func):\n",
    "    model = Sequential()\n",
    "    n_nodes = FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    for i in range(1, n_layers):\n",
    "        if i==1:\n",
    "            model.add(Dense(units = first_layer_nodes,  input_shape=(X_train.shape[1],), activation=activation_func))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            \n",
    "    #Finally, the output layer should have a single node in binary classification\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer = opt, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "##Wrap model into scikit-learn\n",
    "model = KR(build_fn=create_model, epochs = 500, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020D06A7C790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020D08EB48B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best: 0.974711 using {'activation_func': 'softplus', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.590130 (0.100577) with: {'activation_func': 'relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.954794 (0.086219) with: {'activation_func': 'relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.649934 (0.078963) with: {'activation_func': 'relu', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.960595 (0.076039) with: {'activation_func': 'relu', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.669269 (0.075774) with: {'activation_func': 'softplus', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.938424 (0.112710) with: {'activation_func': 'softplus', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.721981 (0.068300) with: {'activation_func': 'softplus', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.974711 (0.046343) with: {'activation_func': 'softplus', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.505785 (0.103078) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.943043 (0.095466) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 200, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "0.593786 (0.095092) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "0.953648 (0.075589) with: {'activation_func': 'leaky_relu', 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n"
     ]
    }
   ],
   "source": [
    "activation_funcs = ['relu', 'softplus', 'leaky_relu'] \n",
    "param_grid = dict(n_layers=[2,3], first_layer_nodes = [200,300], last_layer_nodes = [50],  activation_func = activation_funcs)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, scoring = 'r2')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning - batch size, epoch, optimizer, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer):\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=300, input_shape=(X_train.shape[1],), activation='softplus'))\n",
    " model.add(Dense(units=175, activation='softplus'))\n",
    " model.add(Dense(units=50, activation='softplus'))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    " # Compile model\n",
    " model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mae'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.998642 using {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.915036 (0.030471) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.924286 (0.019220) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.911383 (0.021730) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.074687 (0.015699) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.082496 (0.003961) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.090538 (0.015543) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.176093 (0.033080) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.177306 (0.034115) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.177606 (0.033049) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.956616 (0.018736) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.958521 (0.019133) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.954162 (0.020350) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.694450 (0.002566) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.686299 (0.028560) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.694162 (0.036816) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.946462 (0.025281) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.946852 (0.025157) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.952465 (0.021141) with: {'batch_size': 50, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.956018 (0.028314) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.951206 (0.027289) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.966105 (0.012704) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.185977 (0.028513) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.174314 (0.018265) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.157253 (0.013190) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.171137 (0.033116) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.170507 (0.032657) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.170890 (0.036625) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.984956 (0.009729) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.988356 (0.008857) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.988270 (0.009349) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.898375 (0.027919) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.909479 (0.020448) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.919712 (0.021174) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.983480 (0.010036) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.982243 (0.011154) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.982824 (0.009749) with: {'batch_size': 50, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.974747 (0.013387) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.963045 (0.008415) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.978389 (0.011933) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.324766 (0.003323) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.325982 (0.019787) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.331524 (0.015106) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "0.329395 (0.317562) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "0.154397 (0.360822) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "0.304823 (0.286995) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.998642 (0.000672) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.998091 (0.000301) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.998418 (0.000786) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.968033 (0.017294) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.970300 (0.015666) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.970840 (0.014785) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.995424 (0.003265) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.991661 (0.009726) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.998426 (0.000824) with: {'batch_size': 50, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.909217 (0.028221) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.886592 (0.020625) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.911934 (0.020393) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.065748 (0.010032) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.063868 (0.007076) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.053608 (0.021136) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.176877 (0.034176) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.178271 (0.034617) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.176288 (0.035098) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.949015 (0.019877) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.950282 (0.015355) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.949884 (0.016238) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.673718 (0.023869) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.662986 (0.013770) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.623702 (0.007025) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.930314 (0.030672) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.916817 (0.041700) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.921706 (0.013563) with: {'batch_size': 60, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.964724 (0.017740) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.963864 (0.014639) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.965876 (0.015775) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.156156 (0.020045) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.148325 (0.014144) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.171033 (0.016220) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.172792 (0.032509) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.126237 (0.032958) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.174778 (0.034434) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.980009 (0.013558) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.989109 (0.009397) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.981351 (0.012365) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.898810 (0.023298) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.899983 (0.028656) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.897109 (0.015284) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.979676 (0.011973) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.981358 (0.010854) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.975880 (0.016202) with: {'batch_size': 60, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.974083 (0.018061) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.976868 (0.009799) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.975983 (0.013587) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.306313 (0.010576) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.311891 (0.013446) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.308065 (0.012405) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.012566 (0.115279) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "0.006479 (0.077670) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "0.207303 (0.496148) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.998458 (0.000751) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.998081 (0.000935) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.997935 (0.001336) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.967722 (0.016179) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.968562 (0.016927) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.968409 (0.015727) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.995063 (0.005044) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.997895 (0.000885) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.992779 (0.007531) with: {'batch_size': 60, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.861106 (0.015906) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.878086 (0.024979) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.877143 (0.005222) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.044379 (0.021087) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.044894 (0.004438) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.044000 (0.007223) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.175811 (0.033786) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.177916 (0.035314) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.177674 (0.035318) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.931927 (0.023446) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.931961 (0.009752) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.926431 (0.024929) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.585801 (0.015218) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.527606 (0.044666) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.534164 (0.012907) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.914196 (0.032910) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.916461 (0.027846) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.923960 (0.025129) with: {'batch_size': 80, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.948140 (0.034041) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.958478 (0.022845) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.959908 (0.020435) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.142627 (0.007020) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.117105 (0.023379) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.117230 (0.018459) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.174646 (0.033064) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.175965 (0.035422) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.174929 (0.034980) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.979678 (0.012371) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.977285 (0.014067) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.976012 (0.015455) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.854933 (0.022322) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.869512 (0.018991) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.856681 (0.024610) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.974351 (0.015228) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.965407 (0.016806) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.970708 (0.017391) with: {'batch_size': 80, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.979125 (0.013997) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.973843 (0.016942) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.969607 (0.021085) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.262934 (0.030084) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.283820 (0.009073) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.288447 (0.017127) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "0.170721 (0.405859) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.042407 (0.035717) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.140868 (0.020395) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.997970 (0.001144) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.998064 (0.000918) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.996919 (0.002547) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.958623 (0.020324) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.961138 (0.021342) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.961617 (0.014732) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.997440 (0.001348) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.998090 (0.000441) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.996281 (0.003049) with: {'batch_size': 80, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.855703 (0.003911) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.835603 (0.024450) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.834775 (0.007934) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.024544 (0.007552) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.013579 (0.018865) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.020199 (0.012212) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.177621 (0.035530) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.177972 (0.035468) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.176479 (0.034428) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.910362 (0.013615) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.898539 (0.015734) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.902415 (0.021059) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.463852 (0.014390) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.464289 (0.029160) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.462425 (0.023077) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.899682 (0.016651) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.880493 (0.020613) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.894698 (0.038061) with: {'batch_size': 100, 'epochs': 100, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.930844 (0.031484) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.938393 (0.022884) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.934851 (0.033963) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.091318 (0.021710) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.086844 (0.012739) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.089134 (0.006386) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.176674 (0.033506) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.175650 (0.035764) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.175730 (0.032643) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.969556 (0.017825) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.969142 (0.017509) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.972329 (0.015069) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.817384 (0.009455) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.811863 (0.013458) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.829512 (0.015690) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.969909 (0.016194) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.950439 (0.036754) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.965901 (0.019357) with: {'batch_size': 100, 'epochs': 200, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n",
      "0.966410 (0.020230) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.001}\n",
      "0.973317 (0.014344) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.01}\n",
      "0.974594 (0.014082) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'RMSprop', 'optimizer__learning_rate': 0.1}\n",
      "0.213439 (0.011972) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.001}\n",
      "0.231316 (0.016927) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.01}\n",
      "0.224460 (0.021619) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adagrad', 'optimizer__learning_rate': 0.1}\n",
      "-0.154865 (0.045357) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.001}\n",
      "-0.141983 (0.062225) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.01}\n",
      "-0.170686 (0.033092) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adadelta', 'optimizer__learning_rate': 0.1}\n",
      "0.997980 (0.000950) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.001}\n",
      "0.997469 (0.001391) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.01}\n",
      "0.997694 (0.001448) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adam', 'optimizer__learning_rate': 0.1}\n",
      "0.961657 (0.016631) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.001}\n",
      "0.959406 (0.017604) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.01}\n",
      "0.961120 (0.017031) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Adamax', 'optimizer__learning_rate': 0.1}\n",
      "0.993555 (0.005854) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.001}\n",
      "0.993239 (0.005422) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.01}\n",
      "0.992973 (0.006683) with: {'batch_size': 100, 'epochs': 400, 'model__optimizer': 'Nadam', 'optimizer__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [50, 60, 80, 100]\n",
    "epochs = [100, 200, 400]\n",
    "optimizer = ['RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "\n",
    "# gridsearch\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, model__optimizer=optimizer, optimizer__learning_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, scoring = 'r2')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
